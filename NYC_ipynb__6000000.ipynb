{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diD_WbstrcMq"
   },
   "source": [
    "挂载google硬盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "7le0GohKrafk",
    "outputId": "ace0392d-e558-4101-d141-463f82e090b5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZWgqbolxsRYh"
   },
   "source": [
    "配置kaggle环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "msAi26YmfJTD",
    "outputId": "f1e14391-bff8-4e52-dd2d-5b0227e6ec93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘mydata/NYC-taxi-fare’: File exists\n",
      "mkdir: cannot create directory ‘mydata/keras-loss’: File exists\n",
      "mkdir: cannot create directory ‘mydata/keras-weight’: File exists\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "mkdir: cannot create directory ‘.kaggle’: File exists\n",
      "- path is now set to: /content/NYC-taxi-fare/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir mydata/NYC-taxi-fare\n",
    "!mkdir mydata/keras-loss\n",
    "!mkdir mydata/keras-weight\n",
    "!cd /content\n",
    "!pip install kaggle\n",
    "!mkdir .kaggle\n",
    "import json\n",
    "token={\"username\":\"yingjiaaa\",\"key\":\"ab0c8b444dc434f83c6ba9f6b0055692\"}\n",
    "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(token, file)  \n",
    "!chmod 600 /content/.kaggle/kaggle.json\n",
    "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v /content/NYC-taxi-fare/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwjc1LycsW_F"
   },
   "source": [
    "下载数据并且解压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "cySeunDcZdbu",
    "outputId": "25d84b8b-c2e6-41a0-b756-13c2c400931d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading sample_submission.csv to /content/drive/My Drive/mydata\n",
      "  0% 0.00/335k [00:00<?, ?B/s]\n",
      "100% 335k/335k [00:00<00:00, 22.0MB/s]\n",
      "Downloading test.csv to /content/drive/My Drive/mydata\n",
      "  0% 0.00/960k [00:00<?, ?B/s]\n",
      "100% 960k/960k [00:00<00:00, 29.5MB/s]\n",
      "Downloading train.csv.zip to /content/drive/My Drive/mydata\n",
      "100% 1.56G/1.56G [00:19<00:00, 80.6MB/s]\n",
      "100% 1.56G/1.56G [00:19<00:00, 87.7MB/s]\n",
      "Downloading GCP-Coupons-Instructions.rtf to /content/drive/My Drive/mydata\n",
      "  0% 0.00/486 [00:00<?, ?B/s]\n",
      "100% 486/486 [00:00<00:00, 67.3kB/s]\n",
      "Archive:  /content/drive/My Drive/mydata/train.csv.zip\n",
      "  inflating: /content/drive/My Drive/mydata/train.csv  \n"
     ]
    }
   ],
   "source": [
    "!cd /content/drive/'My Drive'/mydata/\n",
    "!kaggle competitions download -c new-york-city-taxi-fare-prediction -p /content/drive/'My Drive'/mydata/\n",
    "!unzip -d /content/drive/'My Drive'/mydata/ /content/drive/'My Drive'/mydata/train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMhGOz3q2v6p"
   },
   "outputs": [],
   "source": [
    "!cd /content/drive/'My Drive'/mydata/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUXLw8pPy-QI"
   },
   "source": [
    "选择合适的上下车地点（根据经纬度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEGueD_dklXj"
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    # Delimiter lats and lons to NY only\n",
    "    df = df[(-76 <= df['pickup_longitude']) & (df['pickup_longitude'] <= -72)]\n",
    "    df = df[(-76 <= df['dropoff_longitude']) & (df['dropoff_longitude'] <= -72)]\n",
    "    df = df[(38 <= df['pickup_latitude']) & (df['pickup_latitude'] <= 42)]\n",
    "    df = df[(38 <= df['dropoff_latitude']) & (df['dropoff_latitude'] <= 42)]\n",
    "    # Remove possible outliers\n",
    "    df = df[(0 < df['fare_amount']) & (df['fare_amount'] <= 250)]\n",
    "    # Remove inconsistent values\n",
    "    df = df[(df['dropoff_longitude'] != df['pickup_longitude'])]\n",
    "    df = df[(df['dropoff_latitude'] != df['pickup_latitude'])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPxfDL3IzkNi"
   },
   "source": [
    "定义白天上车时间，夜晚上车时间，起点和终点之间的曼哈顿距离；将时间特征拆分为年、月、日、时、周、工作日并且加上白天和夜晚标记；计算起点到终点的曼哈顿距离和欧几里得距离，并且分别计算起点和终点到三个城市的曼哈顿和欧几里得距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKxwCNcSlB_8"
   },
   "outputs": [],
   "source": [
    "def late_night (row):\n",
    "    if (row['hour'] <= 6) or (row['hour'] >= 20):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def night (row):\n",
    "    if ((row['hour'] <= 20) and (row['hour'] >= 16)) and (row['weekday'] < 5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n",
    "\n",
    "\n",
    "def add_time_features(df):\n",
    "    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n",
    "    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n",
    "    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n",
    "    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n",
    "    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n",
    "    df['weekday'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n",
    "    df['pickup_datetime'] =  df['pickup_datetime'].apply(lambda x: str(x))\n",
    "    df['night'] = df.apply (lambda x: night(x), axis=1)\n",
    "    df['late_night'] = df.apply (lambda x: late_night(x), axis=1)\n",
    "    # Drop 'pickup_datetime' as we won't need it anymore\n",
    "    df = df.drop('pickup_datetime', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_coordinate_features(df):\n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    \n",
    "    # Add new features\n",
    "    df['latdiff'] = (lat1 - lat2)\n",
    "    df['londiff'] = (lon1 - lon2)\n",
    "   #print(\"LLLLL\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_distances_features(df):\n",
    "    # Add distances from airpot and downtown\n",
    "    ny = (-74.0063889, 40.7141667)\n",
    "    jfk = (-73.7822222222, 40.6441666667)\n",
    "    ewr = (-74.175, 40.69)\n",
    "    lgr = (-73.87, 40.77)\n",
    "    \n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    df['euclidean'] = (df['latdiff'] ** 2 + df['londiff'] ** 2) ** 0.5\n",
    "    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n",
    "    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n",
    "    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n",
    "    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n",
    "    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n",
    "    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n",
    "    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n",
    "    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n",
    "    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5eC_2jvlHrI"
   },
   "outputs": [],
   "source": [
    "def output_submission(raw_test, prediction, id_column, prediction_column, file_name):\n",
    "    df = pd.DataFrame(prediction, columns=[prediction_column])\n",
    "    df[id_column] = raw_test[id_column]\n",
    "    df[[id_column, prediction_column]].to_csv((file_name), index=False)\n",
    "    print('Output complete')\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_accuracy(history,label_feature):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(label_feature+'model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.savefig(\"/content/drive/My Drive/mydata/keras-loss/\"+label_feature+'model_loss.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRvnpAcblLxT"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"/content/drive/My Drive/mydata/train.csv\"\n",
    "TEST_PATH =\"/content/drive/My Drive/mydata/test.csv\"\n",
    "SUBMISSION_NAME = 'NYC-taxi-fare/submission.csv'\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "id": "omSEhNmCMQrz",
    "outputId": "30e8cc96-360a-4ca4-a73b-0d4fb2442282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "colab_type": "code",
    "id": "XwkC07wVlhFI",
    "outputId": "13170a12-2879-4a48-b1c3-60ebd2092f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import pandas as pd\n",
    "datatypes = {'key': 'str', \n",
    "              'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "\n",
    "# Only a fraction of the whole data\n",
    "train = pd.read_csv(TRAIN_PATH, nrows=DATASET_SIZE)\n",
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "QknXd5VYObtC",
    "outputId": "5729d075-8f68-4bc1-8e67-ed2f06eff834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNqmeuFF7-Vi"
   },
   "source": [
    "各类型的数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAMXjvWclUVv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=[\"time\",\"corordinate\",\"distance\"]\n",
    "def get_subset(a): \n",
    "  sub=[]\n",
    "  to_list=[]\n",
    "  if len(a)==0:\n",
    "    return []\n",
    "  for i in a:\n",
    "    if a.index(i)>0:\n",
    "      to_list.append(i)\n",
    "  sub_list=get_subset(to_list)\n",
    "  if sub_list==[]:\n",
    "    return([[a[0]],[]])\n",
    "  #print(sub_list)\n",
    "  #print(\"yes\")\n",
    "  for i in sub_list:\n",
    "    #print(i)\n",
    "    sub.append(i+[a[0]])\n",
    "    sub.append(i)\n",
    "  return sub\n",
    "how_to_deal=(get_subset(a))\n",
    "del(how_to_deal[7])\n",
    "data_with_diff_feature={}\n",
    "diff_model={}\n",
    "train = clean(train)\n",
    "for i in how_to_deal:\n",
    "  data_deal_method=\"\"\n",
    "  train_temp=train.copy()\n",
    "  test_temp=test.copy()\n",
    "  #print(i)\n",
    "  if  \"time\" in i:\n",
    "    data_deal_method=data_deal_method+\"_time\"\n",
    "    train_temp = add_time_features(train_temp)\n",
    "    test_temp = add_time_features(test_temp)\n",
    "  if \"corordinate\" in i:\n",
    "    data_deal_method=data_deal_method+\"_corordinate\"\n",
    "    add_coordinate_features(train_temp)\n",
    "    add_coordinate_features(test_temp)\n",
    "  if \"latdiff\" in train_temp and \"distance\" in i:\n",
    "    data_deal_method=data_deal_method+\"_distance\"\n",
    "    train_temp = add_distances_features(train_temp)\n",
    "    test_temp =  add_distances_features(test_temp)\n",
    "  data_with_diff_feature[data_deal_method]=[train_temp,test_temp]\n",
    "  del(train_temp)\n",
    "  del(test_temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "cmn92Ydyf2D6",
    "outputId": "b2d8a218-d364-4249-fe2c-89b7e82a79a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_time_corordinate_distance\n",
      "_corordinate_distance\n",
      "_time\n",
      "\n",
      "_time_corordinate\n",
      "_corordinate\n"
     ]
    }
   ],
   "source": [
    "for i in data_with_diff_feature:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-uGFGgtM-Ai"
   },
   "source": [
    "knn回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1E5DafaiBRp9"
   },
   "outputs": [],
   "source": [
    "def knn(X_train,X_val,train_y,val_y,label_features):\n",
    "  global metric\n",
    "  import pandas as pd\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.neighbors import KNeighborsRegressor\n",
    "  knn_reg = KNeighborsRegressor()\n",
    "  #y=pd.DataFrame(train_labels)\n",
    "  #X=pd.DataFrame(train_df_scaled)\n",
    "  #print(X)\n",
    "  #print(pd.DataFrame(y))\n",
    "  #X_train,X_val,train_y,val_y=train_test_split(X,y,random_state=0)  \n",
    "  knn_reg.fit(X_train,train_y)\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(knn_reg.predict(X_val),val_y)\n",
    "  #print(mse**0.5)\n",
    "  metric[label_features]=metric[label_features]+[mse**0.5]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXuL0zS0NJvY"
   },
   "source": [
    "初始化metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLsR6B1ev0he"
   },
   "outputs": [],
   "source": [
    "metric={}\n",
    "metric_1={}\n",
    "del(data_with_diff_feature[\"\"])\n",
    "for i in data_with_diff_feature:\n",
    "  print(i)\n",
    "  metric[i]=[0]\n",
    "metric[\"times\"]=[0]\n",
    "metric[\"data_size\"]=[0]\n",
    "metric[\"way\"]=[0]\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBEg6jZ7lWN3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_evluate(train,test,label_features,data_size):\n",
    "  # Drop unwanted columns\n",
    "  dropped = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','pickup_datetime','key','passenger_count']\n",
    " # print(\"train\")\n",
    "  #print(train)\n",
    "  #print(\"llabel\")\n",
    " # print(label_features)\n",
    "  train,test=train[:data_size],test[:data_size]\n",
    "  print(train.shape)\n",
    "  dropped_columns=[]\n",
    "  for i in dropped:\n",
    "    if i in train.columns:\n",
    "      dropped_columns.append(i)\n",
    "  \n",
    "  train_clean = train.drop(dropped_columns, axis=1)\n",
    "  test_clean = test.drop(dropped_columns + ['key', 'passenger_count'], axis=1)\n",
    "  # peek data\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  train_df, validation_df = train_test_split(train_clean, test_size=0.10, random_state=1)\n",
    "  print((train_df))\n",
    "  # Get labels\n",
    "  train_labels = train_df['fare_amount'].values\n",
    "  validation_labels = validation_df['fare_amount'].values\n",
    "  train_df = train_df.drop(['fare_amount'], axis=1)\n",
    "  validation_df = validation_df.drop(['fare_amount'], axis=1)\n",
    "  # Scale data\n",
    "  # Note: im doing this here with sklearn scaler but, on the Coursera code the scaling is done with Dataflow and Tensorflow\n",
    "  %time\n",
    "  #print(\"2\")\n",
    "  from sklearn import preprocessing\n",
    "  #help(preprocessing.MinMaxScaler)\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    " #print(\"0\")\n",
    "  #print(train_df)\n",
    "  train_df_scaled = scaler.fit_transform(train_df)\n",
    "  print(\"4\")\n",
    "  print(len(validation_df.columns),len(test_clean.columns))\n",
    "  validation_df_scaled = scaler.transform(validation_df)\n",
    "  test_scaled = scaler.transform(test_clean)\n",
    "  print(\"3\")\n",
    "  knn(train_df_scaled,validation_df_scaled,train_labels,validation_labels,label_features)\n",
    "  del(scaler)\n",
    "  #print(train_df_scaled)\n",
    "  from keras.models import Sequential\n",
    "  from keras.layers import Dense, Activation, BatchNormalization\n",
    "  from keras import regularizers, optimizers\n",
    "  model = Sequential()\n",
    "  model.add(Dense(256, activation='relu', input_dim=train_df_scaled.shape[1], activity_regularizer=regularizers.l1(0.01)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(8, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(1))\n",
    "  adam = optimizers.adam(lr=LEARNING_RATE)\n",
    "  model.compile(loss='mse', optimizer=adam, metrics=['mse'])\n",
    "  history = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                    verbose=1, validation_data=(validation_df_scaled, validation_labels), \n",
    "                    shuffle=True)\n",
    "  y_predict=model.predict(x=validation_df_scaled)\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_predict,validation_labels)\n",
    "  global metric#,diff_model\n",
    "  metric[label_features]=metric[label_features]+[mse**0.5]\n",
    "  label_features=str(data_size)+label_features\n",
    "  model.save_weights(\"/content/drive/My Drive/mydata/keras-weight/\"+label_features+\".h5\")\n",
    "  #diff_model[label_features]=model\n",
    "  import matplotlib.pyplot as plt\n",
    "  plot_loss_accuracy(history,label_features)\n",
    "  #pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALakL1wNEjpw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "data_size=[6000000]\n",
    "for j in data_size:\n",
    "  start=time.time()\n",
    "  for i in data_with_diff_feature:\n",
    "    process_evluate(data_with_diff_feature[i][0],data_with_diff_feature[i][1],i,j)\n",
    "  metric[\"times\"]=metric[\"times\"]+[time.time()-start]\n",
    "  metric[\"data_size\"]=metric[\"data_size\"]+[j]\n",
    "  metric[\"times\"]=metric[\"times\"]+[time.time()-start]\n",
    "  metric[\"data_size\"]=metric[\"data_size\"]+[j]\n",
    "  metric[\"way\"]=metric[\"way\"]+['knn']\n",
    "  metric[\"way\"]=metric[\"way\"]+['nero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "fsLGhMQRIN9S",
    "outputId": "275d78d6-e15a-4a1d-8f70-3b9cc5cc2c44"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cde645924a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metric' is not defined"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQFIsBkXopeQ"
   },
   "source": [
    "从文件夹下导入已经处理好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuHbAjJIty1a"
   },
   "outputs": [],
   "source": [
    "#train_clean=pd.read_csv(\"/content/NYC-taxi-fare/train_clean.csv\")\n",
    "#test_clean=pd.read_csv(\"/content/NYC-taxi-fare/test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AdNCe2TqUAH"
   },
   "outputs": [],
   "source": [
    "#model.load_weights(\"/content/NYC-taxi-fare/net\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17hzkdwM-Ji8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkghFjYW-J58"
   },
   "outputs": [],
   "source": [
    "#model.save_weights(\"/content/NYC-taxi-fare/net.h5\")\n",
    "# 将模型权重保存到指定路径，文件类型是HDF5（后缀是.h5）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_n_QF-o3iXr"
   },
   "source": [
    "简单线性预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CkRWGkGZApF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg = KNeighborsRegressor()\n",
    "y=pd.DataFrame(train_labels)\n",
    "X=pd.DataFrame(train_df_scaled)\n",
    "#print(X)\n",
    "#print(pd.DataFrame(y))\n",
    "X_train,X_val,train_y,val_y=train_test_split(X,y,random_state=0)  \n",
    "knn_reg.fit(X_train,train_y)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(knn_reg.predict(X_val),val_y)\n",
    "print(mse**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f24wPDCRLVKZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RxfIt91MmsS"
   },
   "outputs": [],
   "source": [
    "train_df_scaled.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NYC.ipynb-<6000000",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
